{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering 파트 실습 1 - 기초 편\n",
        "\n",
        "Prompt Engineering 관련 아래 기본기들을 익힐 예정\n",
        "- 기본 용어 정리\n",
        "  - Prompt, Role, Response\n",
        "- ChatGPT 간단한 원리\n",
        "  - LLM Next Token Prediction\n",
        "- OpenAI API 호출 방법\n",
        "  - Model, Prompt Text, Temperature\n",
        "  - Max Length\n",
        "- 몇 가지 기본 규칙들\n",
        "\n",
        "*Prompt Engineering 실습 파트는 OpenAI, Anthropic Cookbook, 관련 논문들 및 컨퍼런스 등의 다양한 정보들을 취합한 내용과 강사의 경험을 토대로 진행\n",
        "\n",
        "**실습 비용은 프롬프트 엔지니어링 파트 통틀어서 1000원 미만으로 나올 예정"
      ],
      "metadata": {
        "id": "BOHdL-wnSnaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 기본 용어 정리\n",
        "\n",
        "- Prompt: ChatGPT의 출력을 원하는 방향으로 유도하기 위한 입력 텍스트. Prompt는 보통 질문 또는 지시 형태를 나타냄\n",
        "\n",
        "| Role | Prompt |\n",
        "| --- | --- |\n",
        "| User | 왜 하늘은 하늘색인가요? |\n",
        "\n",
        "- Role: 역할. 크게는 (1) 사용자를 뜻하는 User (2) ChatGPT를 뜻하는 Assistant 그리고 (3) System이 존재\n",
        "  - System은 사용자 Prompt 이전에 입력하는 성능 개선 용도의 Prompt\n",
        "\n",
        "| Role | Prompt |\n",
        "| --- | --- |\n",
        "| Assistant | 하늘은 하늘색인 이유는 대기 중의 분자들이 태양으로부터 오는 빛을 흡수하고 산란시키기 때문입니다. 태양으로부터 오는 빛은 다양한 색상을 가지고 있는데, 대기 중의 분자들은 파란색 빛을 더 많이 흡수하고 산란시키기 때문에 하늘은 파란색으로 보이게 됩니다. 이러한 현상을 레이리 산란이라고 합니다. 따라서 하늘은 하늘색으로 보이는 것입니다. |\n",
        "\n",
        "- Response (또는 Output): 사용자의 Prompt에 대한 LLM의 출력값"
      ],
      "metadata": {
        "id": "ievIxOsWSsrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 간단한 원리 설명 - ChatGPT가 말을 하는 방식에 대하여\n",
        "\n",
        "- Next Token Prediction\n",
        "- ChatGPT 같은 Large Language Model(LLM) 또는 대규모 언어 모델들은 기본적으로 정해진 수의 단어들을 알고 있습니다.\n",
        "  - 예를 들어 메타의 라마2 7B는 32000개, 구글의 젬마 7B는 256000개를 알고 있습니다. (단어를 더 많이 안다고 성능이 좋아지는 것은 아닙니다)\n",
        "- ChatGPT가 예를 들어 10만개의 단어를 알고 있다고 했을 때, 10만개 단어 중 다음 1개의 단어를 예측하는 방식입니다.\n",
        "  - 예시 1. 왜 하늘은 하늘색인가요? ___\n",
        "  - 예시 2. 왜 하늘은 하늘색인가요? 하늘은 하늘색인 이유는 대기 중의 분자들이 태양으로부터 오는 빛을 ___\n",
        "- \"단어\"란 우리가 생각하는 단어는 아닙니다. ChatGPT는 한글이나 영어 문자를 바로 보는게 아니고 이걸 AI모델이 이해 할 수 있는 숫자들로 변환해야하는데 이 숫자들의 수입니다.\n",
        "  - 공식 명칭은 tokens라고 합니다. platform.openai.com/tokenizer 웹사이트에서 tokenizer 기억 나시죠?"
      ],
      "metadata": {
        "id": "h8V-z7WASwd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colab에 OpenAI API Key 등록\n",
        "- 왼쪽 열쇠 모양 버튼 클릭 (보안 비밀 / Secrets 메뉴)\n",
        "- 이름에는 OPENAI_API_KEY 입력\n",
        "- 값에는 OpenAI API Key 복붙하기"
      ],
      "metadata": {
        "id": "P8eN4tv3kT7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPEN_AI_JPMKN_KEY')"
      ],
      "metadata": {
        "id": "0f29uLK7ktrn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI API 호출 방법\n",
        "- OpenAI API 호출 방법이지만 다른 많은 LLM API들도 OpenAI API 형식을 동일하게 따르거나 비슷한 방식의 구조를 채택했습니다."
      ],
      "metadata": {
        "id": "C1FWiaLWi5Ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "fJxivabOmGc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2612999f-8c35-4f13-9d72-15633934d70f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=OPENAI_API_KEY\n",
        ")\n",
        "client.models.list()"
      ],
      "metadata": {
        "id": "brWiz-KGSyqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ef59e6-e766-4fe5-8a66-a6358c0031e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncPage[Model](data=[Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='o1-mini-2024-09-12', created=1725648979, object='model', owned_by='system'), Model(id='o1-preview-2024-09-12', created=1725648865, object='model', owned_by='system'), Model(id='o1-mini', created=1725649008, object='model', owned_by='system'), Model(id='o1-preview', created=1725648897, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system')], object='list')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo-0125',\n",
        "    messages=[{'role': 'user', 'content': '왜 하늘은 하늘색인가요?'}],\n",
        "    temperature=1.0\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "xv34Hi7wS0Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a387e8-f772-4d49-ecdb-3d6c47933f7b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "하늘은 푸르게 보이는 것은 빛의 산란 때문입니다. 대기 중의 공기자체는 무색이지만, 태양으로부터 오는 빛이 대기 중의 수증기, 먼지, 물방울 등의 입자들과 상호작용하여 파란색을 산란시키기 때문에 하늘이 푸르게 보이게 됩니다. 이러한 현상을 레이리 산란이라고 합니다. 따라서 하늘이 하늘색으로 보이는 것은 빛의 산란 현상 때문입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 한 개씩 살펴보기\n",
        "- model: GPT 3.5, GPT-4 버전 별로 선택하실 수 있으며, 보통 더 좋은 성능의 모델일 수록 가격도 그만큼 비싼 편입니다.\n",
        "- messages: Prompt, Role, Response/Output\n",
        "- temperature: 높을 수록 동일한 Prompt에도 매번 다르게 이야기하는 경향이 강해집니다. 0.0으로 셋팅 시 같은 답변으로만 대답합니다.\n"
      ],
      "metadata": {
        "id": "WcGwqKOlS7R9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI API 결과 조금 더 자세히 살펴보기"
      ],
      "metadata": {
        "id": "HeWKS0Edh8-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjY3LKnQiVMX",
        "outputId": "5e785e22-f5f1-459d-f122-eec7b7ed00be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9IEuiGjJAaLjFzXqIY8L13ScUTptI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='하늘은 하늘색인 이유는 대기 중의 분자들이 푸른 빛을 흡수하고 다른 색상의 빛을 반사하기 때문입니다. 태양 빛은 다양한 색상의 빛으로 구성되어 있지만, 대기 중의 분자들이 푸른 빛을 흡수하고 다른 색상의 빛을 반사하게 되어 우리 눈에는 하늘이 푸르게 보이게 됩니다. 이러한 현상을 산란이라고 하며, 이로 인해 하늘은 하늘색으로 보이게 됩니다.', role='assistant', function_call=None, tool_calls=None))], created=1714134260, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=184, prompt_tokens=21, total_tokens=205))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 호출 시 지정하진 않지만 알아야 하는 내용\n",
        "- max length / context window\n",
        "  - 모델마다 입력 및 출력 최대 길이가 다르며, 보통 각 모델 소개 페이지에서 찾을 수 있습니다.\n",
        "  - OpenAI API의 경우 입력 최대 길이 확인: https://platform.openai.com/tokenizer\n",
        "    - 모델 별로 tokenizer는 다릅니다. \"왜 하늘은 하늘색인가요?\" 문장이 어떤 모델한테는 14토큰, 어떤 모델은 29토큰 일 수 있습니다."
      ],
      "metadata": {
        "id": "ZQcFKE_EiWrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기본적인 Prompt 구조\n",
        "\n",
        "Prompt에는 2가지 종류가 존재\n",
        "1. 사용자가 ChatGPT한테 실제로 전달하는 Prompt = User Prompt\n",
        "2. 사용자 Prompt 이전에 오는 해당 LLM 어플리케이션에 적합한 메타 Prompt = System Prompt\n",
        "\n",
        "System Prompt란?\n",
        "- 사용자 Prompt를 전달하기 전에 관련 맥락이나 지침을 설정하는 Prompt\n",
        "  - 페르소나, 어조 등도 설정 할 수 있음\n",
        "- System Prompt 예시\n",
        "  - 출력값 지정 (ex. JSON Formatting)\n",
        "  - 페르소나 및 어조 설정\n",
        "  - 외부 정보 주입\n",
        "  - 모델이 지켜야 할 규칙들 설정\n",
        "\n",
        "왠만한 모델들은 Prompt 입력 시 기본 System Prompt가 붙어있습니다. ChatGPT도 그렇습니다!"
      ],
      "metadata": {
        "id": "yOedQZ_rigVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo-0125',\n",
        "    messages=[\n",
        "        {'role': 'system', 'content': '당신은 물리학 선생님입니다. 초등학교 5학년한테 설명하듯이 아주 쉽고 친근하게 설명해주세요.'},\n",
        "        {'role': 'user', 'content': '왜 하늘은 하늘색인가요?'}\n",
        "    ],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPkXvVQIijn_",
        "outputId": "2ababbd7-ba1f-407f-e3f7-83544783e587"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "하늘은 왜 하늘색일까요? 그 이유는 바로 '태양빛' 때문이에요! 태양은 빛을 내뿜는데, 그 빛은 다양한 색깔을 가지고 있어요. 하지만 그 중에서도 하늘에는 파란색 빛이 가장 많이 닿아요. 이 파란색 빛은 다른 색깔보다 더 많은 에너지를 가지고 있어서 하늘에 반사되는 빛 중에서 파란색이 가장 많이 보이게 되는거죠! 그래서 하늘은 파란색으로 보이는 거에요. 이렇게 태양빛이 하늘을 파랗게 만들어주는거죠!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo-0125',\n",
        "    messages=[\n",
        "        {'role': 'user', 'content': '당신은 물리학 선생님입니다. 초등학교 5학년한테 설명하듯이 아주 쉽고 친근하게 설명해주세요. 왜 하늘은 하늘색인가요?'}\n",
        "    ],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "pxrRAZGgiktj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a27dc6-432f-4d5e-a466-42c5027d286a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "하늘은 왜 하늘색인지 궁금하시죠? 그 이유는 바로 태양빛 때문이에요! 태양은 빛을 내뿜는데, 그 빛은 다양한 색깔을 가지고 있어요. 하지만 우리가 눈으로 볼 때, 그 중에서 파란색 빛이 가장 많이 눈에 띄게 보여요. 그래서 하늘은 파란색으로 보이는 거죠! 이렇게 태양빛이 대기 중의 먼지와 기체들과 상호작용하면서 하늘은 파란색으로 보이게 되는 거에요. 이렇게 하늘은 하늘색이 되는 거죠!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Completion 말고 Stream도 살펴보기\n",
        "- ChatGPT가 문장을 모두 완성하지 않고 각 단어 별로 완성되는데로 바로바로 보여주는 방법입니다."
      ],
      "metadata": {
        "id": "QiyzTtEaio-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stream = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo-0125',\n",
        "    messages=[{'role': 'user', 'content': '왜 하늘은 하늘색인가요?'}],\n",
        "    temperature=0.0,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end='')"
      ],
      "metadata": {
        "id": "8z_JhYKCipim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459f581b-72ca-4aed-c561-893566d8fb0a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "하늘은 하늘색인 이유는 대기 중의 분자들이 햇빛을 흡수하고 산란시키는 과정 때문입니다. 태양으로부터 오는 햇빛은 다양한 색상의 빛으로 구성되어 있지만, 대기 중의 분자들이 햇빛을 흡수하고 다시 방출할 때 파란색 빛이 가장 많이 산란되기 때문에 우리가 보는 하늘은 파란색으로 보이게 됩니다. 이러한 현상을 레이리 산란이라고 하며, 이로 인해 하늘은 파란색으로 보이게 됩니다."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream"
      ],
      "metadata": {
        "id": "m7SLMA1Viqem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66bfba52-af9c-4a27-e242-938889c1a00e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<openai.Stream at 0x7b3458b20250>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 몇 가지 기본 규칙들\n",
        "\n",
        "1. Prompt는 영어로 해야 모델의 제성능을 발휘하는 편\n",
        "   - ChatGPT, Claude 같은 모델들의 학습 데이터 중 큰 비중이 영어로 추정되기 때문\n",
        "   - 학습 데이터가 공개된 라마1의 경우에도 대부분이 영어이며 한글은 극소량만 존재함\n",
        "   - 한글 출력값이 필요하더라도 영어 Prompt를 통해 한글 출력값을 유도하는게 성능이 더 좋을 수 있음\n",
        "2. AI 모델의 출력값은 입력값에 의존도가 매우 높음\n",
        "   - 잘 한 것 같은데 원하는 결과가 안 나오면 입력이 모호하거나 필요한 내용이 빠졌을 수도 있음 (그게 아닌 경우 모델한테 태스크가 너무 어려울 수는 있음)\n",
        "3. Prompt를 이렇게 저렇게 바꿨을 때 \"더 좋아보이는\" 결과보다는 특정 지표에서 유의미하게 더 좋거나 여러 번의 블라인드 테스팅을 통해 더 좋은 Prompt를 정하는 것을 추천\n",
        "   - 다음 챕터인 프롬프트 엔지니어링 라이프사이클에서 자세하게 알려드릴 예정"
      ],
      "metadata": {
        "id": "eBixBk2sitNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정리\n",
        "- Prompt, Role, Output\n",
        "  - Role은 User, Assistant(ex. ChatGPT)\n",
        "  - Prompt는 User, System Prompt\n",
        "- ChatGPT 작동 원리 = Next Token Prediction\n",
        "  - ChatGPT 같은 모든 LLM API는 단어1, 단어2, 단어3이 있을 때 단어3 뒤에 나올 가장 적합한 단어를 선택하는 식으로 출력\n",
        "- OpenAI API 호출 시 model과 messages를 지정해줘야 하며 결과 재현을 위해서는 temperature=0.0 지정을 추천\n",
        "  - 전체 결과값을 한꺼번에 받는 Completions, 실시간으로 바로바로 받을 수 있는 Stream으로 나뉨"
      ],
      "metadata": {
        "id": "OHN8jbJWiu0V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a84WESkhiwnw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}